import os
import io
import time
import re
import httpx
import json
import yt_dlp
import warnings
import concurrent.futures
import difflib
import random
import logging

from typing import List, Optional, Dict, Union
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser
from pydub import AudioSegment, effects

# -------------------------------------------------
# Configuration & Setup
# -------------------------------------------------
warnings.filterwarnings("ignore")
logging.getLogger('httpx').setLevel(logging.WARNING)

# --- API KEYS ---
TYPHOON_BASE_URL = "https://api.opentyphoon.ai/v1"
TYPHOON_API_KEY = "sk-vCE2QnUydpGnzic35kI3IcoTsAeWzb2X3jYCCAXDPmfT2JnN"

GOOGLE_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/openai/"
GOOGLE_API_KEY = "AIzaSyCkjWUucxzLaRPnuklKxKgYP0fUyQhTwHA"
LLM_MODEL_NAME = "gemini-2.0-flash"

# --- TARGET VIDEO ---
YOUTUBE_URL = "https://www.youtube.com/watch?v=opEIqiPzx64"

# --- PATHS ---
DOWNLOAD_DIR = "downloads"
TRANSCRIPT_OUTPUT_DIR = "transcripts_output"
RAW_TRANSCRIPT_FILE = "raw_transcript_full.txt"
CLEAN_TRANSCRIPT_FILE = "final_transcript_clean.txt"
MARKDOWN_FILE = "final_summary_markdown.md"
MASTER_KB_FILE = "knowledge_base.json"
CACHE_FILE = "ticker_cache.json"

# --- SETTINGS ---
CHUNK_DURATION_SEC = 45
OVERLAP_DURATION_SEC = 10
MAX_WORKERS = 5

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Optional Libs
try:
    from duckduckgo_search import DDGS
except ImportError:
    DDGS = None
try:
    import yfinance as yf
except ImportError:
    yf = None

# -------------------------------------------------
# PART 1: AUDIO PROCESSOR
# -------------------------------------------------
class AudioProcessor:
    """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ ASR"""
    @staticmethod
    def preprocess_audio(file_path):
        print(f"üîä Processing Audio: {file_path}")
        print("   - Loading...")
        try:
            audio = AudioSegment.from_file(file_path)
            
            # 1. Convert to Mono (ASR models prefer mono)
            if audio.channels > 1:
                audio = audio.set_channels(1)
                print("   - Converted to Mono")
            
            # 2. Resample to 16000Hz (Native rate for Whisper/Typhoon)
            if audio.frame_rate != 16000:
                audio = audio.set_frame_rate(16000)
                print("   - Resampled to 16kHz")
            
            # 3. Normalize (Adjust volume)
            audio = effects.normalize(audio)
            print("   - Normalized Volume")
            
            return audio
        except Exception as e:
            print(f"‚ùå Error processing audio: {e}")
            return None

# -------------------------------------------------
# PART 2: CONTEXT & DYNAMIC PROMPT
# -------------------------------------------------
class StockContextManager:
    def __init__(self, kb_file=MASTER_KB_FILE):
        self.kb_file = kb_file
        self.sector_data = {}
        self.flat_memory = {} # Map alias -> Ticker
        self.all_tickers = set()
        self.load_kb()

    def load_kb(self):
        if os.path.exists(self.kb_file):
            try:
                with open(self.kb_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if isinstance(data, dict):
                    self.sector_data = data
                    for sector, stocks in data.items():
                        if isinstance(stocks, dict):
                            for ticker, aliases in stocks.items():
                                clean_ticker = ticker.replace('.BK', '')
                                self.all_tickers.add(clean_ticker)
                                self.flat_memory[clean_ticker.lower()] = ticker
                                for alias in aliases:
                                    self.flat_memory[alias.lower()] = ticker
                print(f"üìö Knowledge Base Loaded: {len(self.all_tickers)} Tickers")
            except Exception as e:
                print(f"‚ö†Ô∏è Error loading KB: {e}")

    def get_sector_prompt_str(self):
        lines = []
        for sector, stocks in self.sector_data.items():
            if isinstance(stocks, dict):
                tickers = [t.replace('.BK', '') for t in stocks.keys()]
                lines.append(f"- {sector}: {', '.join(tickers)}")
        return "\n".join(lines)

class DynamicPromptBuilder:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á ASR Prompt ‡πÅ‡∏ö‡∏ö Dynamic ‡∏à‡∏≤‡∏Å Metadata"""
    def __init__(self, context_mgr: StockContextManager):
        self.ctx = context_mgr
        
    def extract_potential_tickers(self, text: str) -> List[str]:
        if not text: return []
        # ‡∏´‡∏≤‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© 2-8 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
        candidates = re.findall(r"\b[A-Z]{2,8}\b", text.upper())
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô KB ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô
        found = []
        blacklist = {"LIVE", "THE", "AND", "FOR", "DAY", "SET", "MAI", "BREAK", "NEWS", "TODAY"}
        for c in candidates:
            if c in self.ctx.all_tickers and c not in blacklist:
                found.append(c)
            elif c not in blacklist and len(c) >= 3:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô KB ‡πÅ‡∏ï‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Title ‡∏Å‡πá‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô
                found.append(c)
        return list(set(found))

    def build_prompt(self, metadata: dict) -> str:
        title = metadata.get('title', '')
        desc = metadata.get('description', '') or ''
        tags = metadata.get('tags', []) or []
        
        # 1. High Priority: ‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Title/Desc/Tags
        combined_text = f"{title} {desc} {' '.join(tags)}"
        priority_tickers = self.extract_potential_tickers(combined_text)
        
        # 2. Medium Priority: ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ
        base_vocab = [
            "‡πÅ‡∏ô‡∏ß‡∏£‡∏±‡∏ö", "‡πÅ‡∏ô‡∏ß‡∏ï‡πâ‡∏≤‡∏ô", "Stop Loss", "Profit Run", "‡∏î‡∏±‡∏ä‡∏ô‡∏µ", "SET Index", "SET50", 
            "‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô", "‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥", "‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™", "Upside", "Downside", "Volume", "RSI", "MACD"
        ]
        
        # 3. Construct Prompt
        prompt_parts = []
        if priority_tickers:
            prompt_parts.append(f"‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡πÉ‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ: {', '.join(priority_tickers)}")
        
        prompt_parts.append(f"‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå: {', '.join(base_vocab)}")
        
        full_prompt = " | ".join(prompt_parts)
        return full_prompt[:800] # ‡∏ï‡∏±‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢

# -------------------------------------------------
# PART 3: SMART RESOLVER (ENTITY VERIFICATION)
# -------------------------------------------------
class MarketTools:
    @staticmethod
    def search_ticker(query: str) -> Optional[str]:
        if DDGS is None: return None
        try:
            search_q = f"‡∏´‡∏∏‡πâ‡∏ô {query} stock symbol ticker settrade"
            with DDGS() as ddgs:
                results = list(ddgs.text(search_q, max_results=2))
                if not results: return None
                blob = " ".join([r.get("title", "") + " " + r.get("body", "") for r in results]).upper()
                candidates = re.findall(r"\b([A-Z]{2,8})\.BK\b", blob)
                if candidates: return candidates[0] + ".BK"
                candidates = re.findall(r"\b([A-Z]{2,8})\b", blob)
                blacklist = {"SET", "MAI", "BKK", "THAI", "PRICE", "NEWS", "STOCK", "TRADE", "DATA", "INFO", "REAL", "TIME"}
                for ticker in candidates:
                    if ticker not in blacklist and len(ticker) >= 2:
                        return ticker
        except: return None
        return None

    @staticmethod
    def verify_ticker(ticker: str) -> bool:
        if yf is None or not ticker: return False
        if "SET.BK" in ticker or "^" in ticker: return False
        try:
            hist = yf.Ticker(ticker).history(period="1d")
            return not hist.empty
        except: return False

class SmartMarketResolver:
    def __init__(self, context_mgr, cache_file=CACHE_FILE):
        self.memory = context_mgr.flat_memory.copy()
        self.cache_file = cache_file
        self.load_cache()

    def load_cache(self):
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.memory.update(json.load(f))
            except: pass

    def save_cache(self, mention, ticker):
        new_data = {}
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    new_data = json.load(f)
            except: pass
        new_data[mention.lower()] = ticker
        with open(self.cache_file, 'w', encoding='utf-8') as f:
            json.dump(new_data, f, ensure_ascii=False, indent=2)
        self.memory[mention.lower()] = ticker

    def resolve(self, mention):
        mention_key = mention.lower().strip()
        # 1. Check Memory/Cache
        if mention_key in self.memory: return self.memory[mention_key]
        
        # 2. Check Strict Pattern (e.g., if mention is already valid ticker like "KBANK")
        if mention.upper() in ctx_mgr.all_tickers:
            return mention.upper() + ".BK"

        # 3. Search
        print(f"    üåê [Searching] '{mention}' ...")
        found = MarketTools.search_ticker(mention)
        time.sleep(1) # Rate limit protection
        
        if found:
            clean = found.upper().strip()
            # Try appending .BK first
            if ".BK" not in clean:
                thai = clean + ".BK"
                if MarketTools.verify_ticker(thai):
                    self.save_cache(mention_key, thai)
                    return thai
            
            # Check raw found
            if MarketTools.verify_ticker(clean):
                self.save_cache(mention_key, clean)
                return clean
                
        return None

# -------------------------------------------------
# PART 4: LANGCHAIN AGENTS (IMPROVED PROMPTS)
# -------------------------------------------------

# Init LLM
llm = ChatOpenAI(
    base_url=GOOGLE_BASE_URL, 
    api_key=GOOGLE_API_KEY, 
    model=LLM_MODEL_NAME, 
    temperature=0.1, 
    max_tokens=8192
)

# --- Prompts ---

# 1. Cleaning
clean_prompt = ChatPromptTemplate.from_messages([
    ("system", "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ Transcript Editor ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà: ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢ (‡πÄ‡∏≠‡πà‡∏≠, ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö, ‡∏≠‡∏≤, ‡πÅ‡∏ö‡∏ö‡∏ß‡πà‡∏≤) ‡∏≠‡∏≠‡∏Å ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏ï‡πà‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç/‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏¥‡πâ‡∏á"),
    ("user", "Transcript:\n\"\"\"{raw_text}\"\"\"")
])
cleaning_chain = clean_prompt | llm | StrOutputParser()

# 2. Correction (Senior Investment Analyst)
correction_system_prompt = (
    "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ **'Senior Investment Analyst Editor'** ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ö‡∏ó‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå **‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô** ‡πÅ‡∏•‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏´‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n"
    "‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô **'‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏á (Paragraphs)'** ‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏´‡∏•\n\n"
    
    "--- ‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Rules) ---\n"
    "1. **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô (Investment Logic & Data Integrity) [‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!]**: \n"
    "   - **Data Audit**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏£‡∏≤‡∏Ñ‡∏≤, ‡πÅ‡∏ô‡∏ß‡∏£‡∏±‡∏ö/‡∏ï‡πâ‡∏≤‡∏ô) ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏° ‡∏´‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ü‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô\n"
    "   - **Logic Consistency**: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏ó‡∏≤‡∏á‡∏ï‡∏£‡∏£‡∏Å‡∏∞ (‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏∏‡πâ‡∏ô '‡∏•‡∏á‡πÅ‡∏£‡∏á' ‡πÅ‡∏ï‡πà‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ '‡πÄ‡∏Ç‡πâ‡∏≤‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°') ‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå\n"
    "   - **Contextual Ticker Check**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ò‡∏µ‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏±‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πà‡∏≤‡∏ß‡πÇ‡∏£‡∏á‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ ‡∏Å‡πá‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô GULF, GPSC ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏´‡∏∏‡πâ‡∏ô‡∏Ç‡∏ô‡∏°)\n"
    "2. **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô (Completeness)**: **‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô/‡∏´‡∏∏‡πâ‡∏ô‡∏≠‡∏≠‡∏Å‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î!** ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏ö‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô‡∏à‡∏ô‡∏à‡∏ö\n"
    "3. **‡πÅ‡∏Å‡πâ‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î (Ticker Correction)**: ‡πÅ‡∏Å‡πâ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏ú‡∏¥‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô (Ticker) ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡πÄ‡∏ä‡πà‡∏ô '‡∏Å‡∏£‡∏≤‡∏ü' -> 'GULF', '‡πÄ‡∏≠‡πá‡∏ô‡πÅ‡∏Ñ‡∏õ' -> 'NCAP', '‡∏ö‡∏µ‡πÑ‡∏≠‡πÄ‡∏≠' -> 'BRI') ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö\n"
    "4. **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (Formatting)**: \n"
    "   - ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô **'‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤ (Paragraph)'** ‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏±‡∏ô (Narrative Style)\n"
    "   - **‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ Bullet Points ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤** ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ\n\n"
    "**Output**: ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô Transcript ‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏á"
)
correction_prompt = ChatPromptTemplate.from_messages([
    ("system", correction_system_prompt),
    ("user", "Transcript to Correct:\n\"\"\"{clean_text}\"\"\"")
])
correction_chain = correction_prompt | llm | StrOutputParser()

# 3. NER (Structured Output)
class StockEntity(BaseModel):
    text_found: str = Field(...)
    
class EntityList(BaseModel):
    entities: List[StockEntity]

ner_prompt = ChatPromptTemplate.from_messages([
    ("system", "‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô (Ticker) ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ JSON"),
    ("user", "Text:\n\"\"\"{text}\"\"\"")
])
ner_chain = ner_prompt | llm.with_structured_output(EntityList)

# 4. Summary (Infographic Lead) - [UPDATED: NO BOLD]
summary_system_prompt = (
    "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ **'Infographic Content Lead'** ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏¢‡πà‡∏≠‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô\n"
    "‡πÇ‡∏à‡∏ó‡∏¢‡πå: ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Transcript ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Infographic ‡∏ó‡∏µ‡πà **'‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å (Insightful)'** ‡πÅ‡∏•‡∏∞ **'‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô'** ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡πà‡∏≠\n\n"
    
    "--- ‡∏Å‡∏é‡πÄ‡∏´‡∏•‡πá‡∏Å‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (Strict Rules) ---\n"
    "1. **Clean Text (No Bold)**: ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ ** (‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏≤) ‡πÉ‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÇ‡∏î‡∏¢‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Header #)\n"
    "2. **‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î (Must be Detailed)**: ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Bullet Point ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ **'‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏ (Why)'**, **'‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Key Numbers)'**, ‡∏´‡∏£‡∏∑‡∏≠ **'‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ö‡∏ß‡∏Å/‡∏•‡∏ö (Catalysts)'** ‡πÄ‡∏™‡∏°‡∏≠\n"
    "   - *‡πÅ‡∏¢‡πà:* ‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏ü‡πÅ‡∏ô‡∏ô‡∏ã‡πå‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô\n"
    "   - *‡∏î‡∏µ:* ‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏ü‡πÅ‡∏ô‡∏ô‡∏ã‡πå‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô ‡∏£‡∏±‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏á‡∏ö THANI ‡∏Å‡∏≥‡πÑ‡∏£‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏≤‡∏î‡∏ó‡∏µ‡πà 300 ‡∏•‡∏ö. ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏•‡∏î‡∏•‡∏á\n"
    "3. **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á**: ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡∏£‡∏≤‡∏Ñ‡∏≤, ‡πÅ‡∏ô‡∏ß‡∏£‡∏±‡∏ö/‡∏ï‡πâ‡∏≤‡∏ô) ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πä‡∏∞ 100% ‡∏ï‡∏≤‡∏° Transcript\n"
    "4. **‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô**: ‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà (UPPERCASE) ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏≤\n"
    "5. **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á**: ‡πÉ‡∏ä‡πâ Header (#, ##) ‡πÅ‡∏•‡∏∞ Bullet Points (-) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n"
    "6. **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô**: ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏¥‡πâ‡∏á ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô Technical ‡πÅ‡∏•‡∏∞ Strategy\n\n"
    
    "--- ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á (Mandatory Template) ---\n"
    "# ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏ß‡∏∞‡∏ï‡∏•‡∏≤‡∏î\n"
    "## ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ï‡∏•‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n"
    "   - (‡∏™‡∏£‡∏∏‡∏õ‡∏î‡∏±‡∏ä‡∏ô‡∏µ, ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢, ‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)\n"
    "## ‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç\n"
    "   - (‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏° ‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)\n"
    "## ‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á\n"
    "   - (‡∏£‡∏∞‡∏ö‡∏∏‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏•‡∏á ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏ ‡πÄ‡∏ä‡πà‡∏ô ‡∏á‡∏ö‡πÅ‡∏¢‡πà, ‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡∏ö, ‡∏´‡∏£‡∏∑‡∏≠ 52-week low)\n"
    "## ‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå (Strategy Picks)\n"
    "   - (‡∏™‡∏£‡∏∏‡∏õ‡∏ò‡∏µ‡∏°‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•)\n"
    "## ‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ (Technical Picks)\n"
    "   - (‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏° Pattern ‡∏Å‡∏£‡∏≤‡∏ü ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏Ç‡πÅ‡∏ô‡∏ß‡∏£‡∏±‡∏ö/‡πÅ‡∏ô‡∏ß‡∏ï‡πâ‡∏≤‡∏ô/Stop Loss ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô)\n"
    "## ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡∏≠‡∏∑‡πà‡∏ô‡πÜ\n"
    "   - (‡∏Ç‡πà‡∏≤‡∏ß‡∏£‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡πÅ‡∏•‡∏∞‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏ö‡∏à‡∏∞‡∏î‡∏µ)\n\n"
    
    "[MAPPING Reference] (‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ô‡∏µ‡πâ)\n{mapping_str}"
)
summary_prompt = ChatPromptTemplate.from_messages([
    ("system", summary_system_prompt),
    ("user", "Transcript:\n\"\"\"{corrected_text}\"\"\"")
])
summary_chain = summary_prompt | llm | StrOutputParser()

# -------------------------------------------------
# PART 5: MAIN LOGIC
# -------------------------------------------------

# Global Objects
ctx_mgr = StockContextManager()
prompt_builder = DynamicPromptBuilder(ctx_mgr)
resolver = SmartMarketResolver(ctx_mgr)

# Typhoon Client
try:
    http_client = httpx.Client(timeout=120.0)
    from openai import OpenAI
    asr_client = OpenAI(base_url=TYPHOON_BASE_URL, api_key=TYPHOON_API_KEY, http_client=http_client)
except Exception as e:
    print(f"‚ùå Error init Typhoon Client: {e}"); exit()

def transcribe_chunk(chunk_data, chunk_index, dynamic_prompt):
    retries = 0
    while retries < 3:
        try:
            file_like = io.BytesIO(chunk_data)
            file_like.name = f"chunk_{chunk_index}.wav"
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Typhoon ‡∏û‡∏£‡πâ‡∏≠‡∏° Dynamic Prompt
            response = asr_client.audio.transcriptions.create(
                model="typhoon-asr-realtime", 
                file=file_like, 
                language="th", 
                prompt=dynamic_prompt, # <--- KEY POINT
                temperature=0.2
            )
            print(f"    ‚úÖ [Chunk {chunk_index:02d}] Done.")
            return response.text
        except Exception as e:
            retries += 1; print(f"    ‚ö†Ô∏è [Chunk {chunk_index:02d}] Error: {e}"); time.sleep(1)
    return ""

def merge_transcriptions(transcripts):
    if not transcripts: return ""
    full_text = transcripts[0].strip()
    for i in range(1, len(transcripts)):
        prev = full_text
        curr = transcripts[i].strip()
        if not curr: continue
        # Simple overlap matching
        matcher = difflib.SequenceMatcher(None, prev[-500:], curr[:500])
        match = matcher.find_longest_match(0, len(prev[-500:]), 0, 500)
        if match.size > 10: 
            full_text += curr[match.b + match.size:]
        else: 
            full_text += " " + curr
    return re.sub(r"\s+", " ", full_text).strip()

def main():
    if not os.path.exists(TRANSCRIPT_OUTPUT_DIR): os.makedirs(TRANSCRIPT_OUTPUT_DIR)
    
    # 1. Get Video Metadata & Download
    print("\n‚¨áÔ∏è  [Step 1] Fetching Metadata & Audio...")
    ydl_opts = {
        "format": "bestaudio/best",
        "postprocessors": [{"key": "FFmpegExtractAudio", "preferredcodec": "mp3", "preferredquality": "192"}],
        "outtmpl": os.path.join(DOWNLOAD_DIR, "%(id)s.%(ext)s"),
        "quiet": True, "no_warnings": True
    }
    
    video_meta = {}
    audio_filename = ""
    
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        # 1.1 Extract Info First
        info = ydl.extract_info(YOUTUBE_URL, download=False)
        video_meta = {
            'title': info.get('title', ''),
            'description': info.get('description', ''),
            'tags': info.get('tags', [])
        }
        print(f"    üìÑ Title: {video_meta['title']}")
        
        # 1.2 Generate Dynamic Prompt
        dynamic_prompt = prompt_builder.build_prompt(video_meta)
        print(f"    üéØ Dynamic Prompt: {dynamic_prompt}")
        
        # 1.3 Download
        print("    ‚¨áÔ∏è  Downloading...")
        ydl.download([YOUTUBE_URL])
        audio_filename = ydl.prepare_filename(info).replace(".webm", ".mp3").replace(".m4a", ".mp3")
        if not os.path.exists(audio_filename):
            # Fallback check
            audio_filename = os.path.join(DOWNLOAD_DIR, f"{info['id']}.mp3")

    # 2. Preprocess Audio
    print("\nüîä [Step 2] Preprocessing Audio...")
    audio = AudioProcessor.preprocess_audio(audio_filename)
    if not audio: return

    # 3. Transcribe
    print(f"\nüöÄ [Step 3] Transcribing with Typhoon (Prompt Aware)...")
    chunk_ms = CHUNK_DURATION_SEC * 1000
    overlap_ms = OVERLAP_DURATION_SEC * 1000
    chunks = []
    
    # Create chunks
    for i, s in enumerate(range(0, len(audio), chunk_ms - overlap_ms)):
        buf = io.BytesIO()
        chunk_segment = audio[s:min(s+chunk_ms, len(audio))]
        chunk_segment.export(buf, format="wav")
        chunks.append({"data": buf.getvalue(), "index": i})
    
    # Parallel Transcribe
    results = {}
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        futures = {ex.submit(transcribe_chunk, c["data"], c["index"], dynamic_prompt): c["index"] for c in chunks}
        for f in concurrent.futures.as_completed(futures):
            results[futures[f]] = f.result()
            
    raw_text = merge_transcriptions([results[i] for i in sorted(results.keys())])
    
    with open(os.path.join(TRANSCRIPT_OUTPUT_DIR, RAW_TRANSCRIPT_FILE), "w", encoding="utf-8") as f:
        f.write(raw_text)
    print(f"    ‚úÖ Raw Transcript Saved ({len(raw_text)} chars)")

    # 4. Cleaning
    print("\nüß† [Step 4] Cleaning...")
    clean_text = cleaning_chain.invoke({"raw_text": raw_text})
    
    # 5. Correction (Senior Analyst)
    print("\nüß† [Step 5] Correcting with Investment Logic...")
    corrected_text = correction_chain.invoke({"clean_text": clean_text})
    with open(os.path.join(TRANSCRIPT_OUTPUT_DIR, CLEAN_TRANSCRIPT_FILE), "w", encoding="utf-8") as f:
        f.write(corrected_text)
        
    # 6. NER & Resolution
    print("\nü§ñ [Step 6] Identifying & Verifying Tickers...")
    try:
        ner_res = ner_chain.invoke({"text": corrected_text[:30000]})
        entities = ner_res.entities
    except: entities = []
    
    mappings = []
    seen = set()
    for ent in entities:
        if ent.text_found in seen: continue
        seen.add(ent.text_found)
        
        real_ticker = resolver.resolve(ent.text_found)
        if real_ticker:
            clean_tk = real_ticker.replace('.BK', '')
            mappings.append(f"- {ent.text_found} -> {clean_tk}")
            print(f"    ‚úÖ {ent.text_found} -> {clean_tk}")
    
    mapping_str = "\n".join(mappings)

    # 7. Final Summary
    print("\nüìù [Step 7] Generating Final Infographic Summary...")
    final_md = summary_chain.invoke({
        "corrected_text": corrected_text,
        "mapping_str": mapping_str
    })
    
    with open(os.path.join(TRANSCRIPT_OUTPUT_DIR, MARKDOWN_FILE), "w", encoding="utf-8") as f:
        f.write(final_md)
        
    print(f"\n‚úÖ SUCCESS! All files saved in '{TRANSCRIPT_OUTPUT_DIR}'")
    
    # ---------------------------------------------------------
    # DISPLAY BOTH OUTPUTS (Output 1 & Output 2)
    # ---------------------------------------------------------
    
    print("\n" + "="*20 + " OUTPUT 1: FINAL TRANSCRIPT (FULL NARRATIVE) " + "="*20 + "\n")
    print(corrected_text)
    print("\n" + "="*22 + " END OUTPUT 1 " + "="*22 + "\n")

    print("\n" + "="*20 + " OUTPUT 2: FINAL SUMMARY (INFOGRAPHIC) " + "="*20 + "\n")
    print(final_md)
    print("\n" + "="*25 + " END OUTPUT 2 " + "="*25 + "\n")

if __name__ == "__main__":
    main()