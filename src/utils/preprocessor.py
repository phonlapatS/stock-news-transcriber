#!/usr/bin/env python3
"""
Pre-processing Layer - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á LLM
Multi-layer defense: Layer 1

Features:
1. Filler word removal (regex-based, ‡πÑ‡∏°‡πà‡∏û‡∏∂‡πà‡∏á LLM)
2. Number word conversion (Thai ‚Üí Arabic)
3. Proper noun pattern matching (Dow Jones, NASDAQ, etc.)
4. ASR error pattern correction
"""

import re
from typing import Tuple, Dict, List
from collections import OrderedDict


class TextPreprocessor:
    """
    Pre-processing layer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢ pattern matching
    ‡πÑ‡∏°‡πà‡∏û‡∏∂‡πà‡∏á LLM ‚Üí ‡πÄ‡∏£‡πá‡∏ß, ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥, ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏∑‡∏≠‡∏á quota
    """
    
    def __init__(self):
        # Filler words ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á (comprehensive list)
        self.filler_words = [
            # Common fillers
            r'\b‡∏ô‡∏∞‡∏Æ‡∏∞\b', r'\b‡πÄ‡∏ô‡∏≤‡∏∞\b', r'\b‡∏≠‡πà‡∏≤\b', r'\b‡πÄ‡∏≠‡πà‡∏≠\b', r'\b‡∏≠‡∏∑‡∏°\b',
            r'\b‡∏à‡πâ‡∏≤\b', r'\b‡∏à‡πä‡∏∞\b', r'\b‡∏≠‡πã‡∏≠\b', r'\b‡πÄ‡∏≠‡∏≠\b',
            
            # Polite particles (‡∏•‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
            r'\b‡∏Ñ‡∏£‡∏±‡∏ö\b', r'\b‡∏Ñ‡πà‡∏∞\b', r'\b‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö\b', r'\b‡∏ô‡∏∞‡∏Ñ‡∏∞\b',
            r'\b‡∏Ñ‡∏£‡∏±‡∏ö‡∏ú‡∏°\b', r'\b‡∏Ñ‡πà‡∏∞‡∏Ñ‡∏∏‡∏ì\b',
            
            # Hesitation
            r'\b‡πÄ‡∏≠‡πà‡∏≠\s+', r'\b‡∏≠‡∏∑‡∏°\s+', r'\b‡∏≠‡πà‡∏≤\s+',
        ]
        
        # Number word mappings (Thai ‚Üí Arabic)
        self.number_words = {
            '‡∏®‡∏π‡∏ô‡∏¢‡πå': '0', '‡∏´‡∏ô‡∏∂‡πà‡∏á': '1', '‡∏™‡∏≠‡∏á': '2', '‡∏™‡∏≤‡∏°': '3', '‡∏™‡∏µ‡πà': '4',
            '‡∏´‡πâ‡∏≤': '5', '‡∏´‡∏Å': '6', '‡πÄ‡∏à‡πá‡∏î': '7', '‡πÅ‡∏õ‡∏î': '8', '‡πÄ‡∏Å‡πâ‡∏≤': '9',
            '‡∏™‡∏¥‡∏ö': '10', '‡∏¢‡∏µ‡πà‡∏™‡∏¥‡∏ö': '20', '‡∏™‡∏≤‡∏°‡∏™‡∏¥‡∏ö': '30', '‡∏™‡∏µ‡πà‡∏™‡∏¥‡∏ö': '40',
            '‡∏´‡πâ‡∏≤‡∏™‡∏¥‡∏ö': '50', '‡∏´‡∏Å‡∏™‡∏¥‡∏ö': '60', '‡πÄ‡∏à‡πá‡∏î‡∏™‡∏¥‡∏ö': '70', '‡πÅ‡∏õ‡∏î‡∏™‡∏¥‡∏ö': '80',
            '‡πÄ‡∏Å‡πâ‡∏≤‡∏™‡∏¥‡∏ö': '90',
            '‡∏£‡πâ‡∏≠‡∏¢': '100', '‡∏û‡∏±‡∏ô': '1000', '‡∏´‡∏°‡∏∑‡πà‡∏ô': '10000', '‡πÅ‡∏™‡∏ô': '100000',
            '‡∏•‡πâ‡∏≤‡∏ô': '1000000',
            '‡∏à‡∏∏‡∏î': '.', '‡∏Ñ‡∏£‡∏∂‡πà‡∏á': '0.5'
        }
        
        # Proper noun patterns (regex-based)
        self.proper_noun_patterns = [
            # Dow Jones
            (r'\b(‡∏î‡∏≤‡∏ß\s*‡πÇ‡∏à‡∏ô‡∏™‡πå|‡∏î‡∏≤‡∏ß\s*‡πÇ‡∏à‡∏£‡∏ô‡πå|‡∏î‡∏≤‡πÄ‡∏ó‡∏≤|Datao)\b', 'Dow Jones'),
            # NASDAQ
            (r'\b(‡πÅ‡∏ô‡∏™‡πÅ‡∏î‡πá‡∏Å|‡∏ô‡∏±‡∏™‡πÅ‡∏î‡πá‡∏Å|‡∏ô‡∏≤‡∏™‡πÅ‡∏î‡πá‡∏Å)\b', 'NASDAQ'),
            # S&P 500
            (r'\b(‡πÄ‡∏≠‡∏™\s*‡πÅ‡∏≠‡∏ô‡∏î‡πå\s*‡∏û‡∏µ|‡πÄ‡∏≠‡∏™\s*‡πÅ‡∏≠‡∏ô‡∏î‡πå\s*‡∏û‡∏µ\s*‡∏´‡πâ‡∏≤‡∏£‡πâ‡∏≠‡∏¢|S\s*&\s*P\s*500)\b', 'S&P 500'),
            # SET Index
            (r'\b(‡πÄ‡∏ã‡πá‡∏ï\s*‡πÄ‡∏î‡πá‡∏Å|‡πÄ‡∏ã‡∏ó\s*‡πÄ‡∏î‡πá‡∏Å|‡πÄ‡∏ã‡∏ô\s*‡πÄ‡∏î‡πá‡∏Å|‡πÄ‡∏ã‡πá‡∏ô\s*‡πÄ‡∏î‡πá‡∏Å|‡πÄ‡∏ã‡πá‡∏î\s*‡πÄ‡∏î‡πá‡∏Å)\b', 'SET Index'),
        ]
        
        # [IMPROVED] Load ASR error patterns from asr_errors.json
        self.asr_error_patterns = self._load_asr_error_patterns()
        
        # Compile regex patterns for performance
        self.filler_pattern = re.compile('|'.join(self.filler_words), re.IGNORECASE)
        
    def remove_filler_words(self, text: str) -> Tuple[str, int]:
        """
        ‡∏•‡∏ö filler words ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            
        Returns:
            Tuple of (cleaned_text, num_removed)
        """
        original = text
        cleaned = self.filler_pattern.sub('', text)
        
        # Clean up multiple spaces
        cleaned = re.sub(r'\s+', ' ', cleaned)
        cleaned = cleaned.strip()
        
        # Count removed (approximate)
        num_removed = len(re.findall('|'.join(self.filler_words), original, re.IGNORECASE))
        
        return cleaned, num_removed
    
    def convert_number_words(self, text: str) -> Tuple[str, int]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏≠‡∏≤‡∏£‡∏ö‡∏¥‡∏Å
        
        Examples:
            "‡∏™‡∏≤‡∏°‡∏ö‡∏≤‡∏ó" ‚Üí "3 ‡∏ö‡∏≤‡∏ó"
            "‡∏™‡∏≠‡∏á‡∏û‡∏±‡∏ô‡∏ö‡∏≤‡∏ó" ‚Üí "2,000 ‡∏ö‡∏≤‡∏ó"
            "‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏à‡∏∏‡∏î‡∏´‡πâ‡∏≤" ‚Üí "1.5"
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            
        Returns:
            Tuple of (converted_text, num_conversions)
        """
        converted = text
        num_conversions = 0
        
        # Pattern: number word + "‡∏ö‡∏≤‡∏ó" or number word + "‡∏à‡∏∏‡∏î" + number
        patterns = [
            # Simple numbers: "‡∏™‡∏≤‡∏°‡∏ö‡∏≤‡∏ó" ‚Üí "3 ‡∏ö‡∏≤‡∏ó"
            (r'\b(‡∏´‡∏ô‡∏∂‡πà‡∏á|‡∏™‡∏≠‡∏á|‡∏™‡∏≤‡∏°|‡∏™‡∏µ‡πà|‡∏´‡πâ‡∏≤|‡∏´‡∏Å|‡πÄ‡∏à‡πá‡∏î|‡πÅ‡∏õ‡∏î|‡πÄ‡∏Å‡πâ‡∏≤|‡∏™‡∏¥‡∏ö)\s*‡∏ö‡∏≤‡∏ó\b', 
             lambda m: f"{self._word_to_number(m.group(1))} ‡∏ö‡∏≤‡∏ó"),
            
            # Complex numbers: "‡∏™‡∏≠‡∏á‡∏û‡∏±‡∏ô‡∏ö‡∏≤‡∏ó" ‚Üí "2,000 ‡∏ö‡∏≤‡∏ó"
            (r'\b(‡∏´‡∏ô‡∏∂‡πà‡∏á|‡∏™‡∏≠‡∏á|‡∏™‡∏≤‡∏°|‡∏™‡∏µ‡πà|‡∏´‡πâ‡∏≤|‡∏´‡∏Å|‡πÄ‡∏à‡πá‡∏î|‡πÅ‡∏õ‡∏î|‡πÄ‡∏Å‡πâ‡∏≤|‡∏™‡∏¥‡∏ö)\s*(‡∏£‡πâ‡∏≠‡∏¢|‡∏û‡∏±‡∏ô|‡∏´‡∏°‡∏∑‡πà‡∏ô|‡πÅ‡∏™‡∏ô|‡∏•‡πâ‡∏≤‡∏ô)\s*‡∏ö‡∏≤‡∏ó\b',
             lambda m: f"{self._word_to_number(m.group(1))}{self._word_to_number(m.group(2))} ‡∏ö‡∏≤‡∏ó"),
            
            # Decimals: "‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏à‡∏∏‡∏î‡∏´‡πâ‡∏≤" ‚Üí "1.5"
            (r'\b(‡∏´‡∏ô‡∏∂‡πà‡∏á|‡∏™‡∏≠‡∏á|‡∏™‡∏≤‡∏°|‡∏™‡∏µ‡πà|‡∏´‡πâ‡∏≤|‡∏´‡∏Å|‡πÄ‡∏à‡πá‡∏î|‡πÅ‡∏õ‡∏î|‡πÄ‡∏Å‡πâ‡∏≤|‡∏™‡∏¥‡∏ö)\s*‡∏à‡∏∏‡∏î\s*(‡∏´‡∏ô‡∏∂‡πà‡∏á|‡∏™‡∏≠‡∏á|‡∏™‡∏≤‡∏°|‡∏™‡∏µ‡πà|‡∏´‡πâ‡∏≤|‡∏´‡∏Å|‡πÄ‡∏à‡πá‡∏î|‡πÅ‡∏õ‡∏î|‡πÄ‡∏Å‡πâ‡∏≤|‡∏™‡∏¥‡∏ö)\b',
             lambda m: f"{self._word_to_number(m.group(1))}.{self._word_to_number(m.group(2))}"),
        ]
        
        for pattern, replacement in patterns:
            matches = list(re.finditer(pattern, converted))
            if matches:
                # Replace from end to start to preserve positions
                for match in reversed(matches):
                    converted = converted[:match.start()] + replacement(match) + converted[match.end():]
                    num_conversions += 1
        
        return converted, num_conversions
    
    def _word_to_number(self, word: str) -> str:
        """Convert Thai number word to Arabic digit"""
        return self.number_words.get(word, word)
    
    def _load_asr_error_patterns(self) -> List[Tuple[str, str]]:
        """Load ASR error patterns from asr_errors.json"""
        patterns = []
        
        try:
            import json
            import os
            
            errors_file = "asr_errors.json"
            if os.path.exists(errors_file):
                with open(errors_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # Extract common patterns (if structured)
                if isinstance(data, dict) and 'errors' in data:
                    error_list = data['errors']
                elif isinstance(data, list):
                    error_list = data
                else:
                    error_list = []
                
                # Get last 50 entries (most recent)
                for entry in error_list[-50:]:
                    if isinstance(entry, dict):
                        raw = entry.get('raw', '')
                        corrected = entry.get('corrected', '')
                        
                        if raw and corrected and raw != corrected:
                            # Create regex pattern (escape special chars)
                            pattern = re.escape(raw)
                            patterns.append((pattern, corrected))
        except Exception as e:
            # Silently fail and use fallback
            pass
        
        # Fallback to minimal hardcoded patterns
        if not patterns:
            patterns = [
                (r'\b‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏™‡∏±‡∏ï‡∏ß‡πå\b', '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏™‡∏¥‡∏ö'),
            ]
        
        return patterns
    
    def fix_proper_nouns(self, text: str) -> Tuple[str, int]:
        """
        ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç proper nouns ‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÅ‡∏•‡πâ‡∏ß
        
        Examples:
            "‡∏î‡∏≤‡∏ß‡πÇ‡∏à‡∏ô‡∏™‡πå" ‚Üí "Dow Jones"
            "‡πÅ‡∏ô‡∏™‡πÅ‡∏î‡πá‡∏Å" ‚Üí "NASDAQ"
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            
        Returns:
            Tuple of (fixed_text, num_fixes)
        """
        fixed = text
        num_fixes = 0
        
        for pattern, replacement in self.proper_noun_patterns:
            matches = list(re.finditer(pattern, fixed, re.IGNORECASE))
            if matches:
                # Replace from end to start
                for match in reversed(matches):
                    fixed = fixed[:match.start()] + replacement + fixed[match.end():]
                    num_fixes += 1
        
        return fixed, num_fixes
    
    def fix_asr_errors(self, text: str) -> Tuple[str, int]:
        """
        ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ASR errors ‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÅ‡∏•‡πâ‡∏ß
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            
        Returns:
            Tuple of (fixed_text, num_fixes)
        """
        fixed = text
        num_fixes = 0
        
        for pattern, replacement in self.asr_error_patterns:
            matches = list(re.finditer(pattern, fixed, re.IGNORECASE))
            if matches:
                for match in reversed(matches):
                    fixed = fixed[:match.start()] + replacement + fixed[match.end():]
                    num_fixes += 1
        
        # Clean up multiple spaces
        fixed = re.sub(r'\s+', ' ', fixed)
        
        return fixed, num_fixes
    
    def preprocess(self, text: str, verbose: bool = False) -> Tuple[str, Dict[str, int]]:
        """
        Pre-process ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            verbose: ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            
        Returns:
            Tuple of (preprocessed_text, stats_dict)
        """
        stats = {
            'filler_removed': 0,
            'numbers_converted': 0,
            'proper_nouns_fixed': 0,
            'asr_errors_fixed': 0
        }
        
        processed = text
        
        # Step 1: Remove filler words
        processed, stats['filler_removed'] = self.remove_filler_words(processed)
        
        # Step 2: Convert number words
        processed, stats['numbers_converted'] = self.convert_number_words(processed)
        
        # Step 3: Fix proper nouns
        processed, stats['proper_nouns_fixed'] = self.fix_proper_nouns(processed)
        
        # Step 4: Fix ASR errors
        processed, stats['asr_errors_fixed'] = self.fix_asr_errors(processed)
        
        if verbose:
            total_fixes = sum(stats.values())
            if total_fixes > 0:
                print(f"   üîß Pre-processing: {total_fixes} fixes applied")
                if stats['filler_removed'] > 0:
                    print(f"      - Removed {stats['filler_removed']} filler words")
                if stats['numbers_converted'] > 0:
                    print(f"      - Converted {stats['numbers_converted']} number words")
                if stats['proper_nouns_fixed'] > 0:
                    print(f"      - Fixed {stats['proper_nouns_fixed']} proper nouns")
                if stats['asr_errors_fixed'] > 0:
                    print(f"      - Fixed {stats['asr_errors_fixed']} ASR errors")
        
        return processed, stats


# Convenience function
def preprocess_text(text: str, verbose: bool = False) -> str:
    """
    Pre-process ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (convenience function)
    
    Args:
        text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        verbose: ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        
    Returns:
        Pre-processed text
    """
    preprocessor = TextPreprocessor()
    processed, _ = preprocessor.preprocess(text, verbose=verbose)
    return processed

