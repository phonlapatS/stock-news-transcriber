import os
import io
import time
import random
import difflib
import re
import httpx
from openai import OpenAI, RateLimitError, APITimeoutError
from pydub import AudioSegment
import concurrent.futures

# ---------------- CONFIGURATION ----------------

# 1. Typhoon ASR (‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á - ‡πÄ‡∏Å‡πà‡∏á‡πÑ‡∏ó‡∏¢‡∏™‡∏∏‡∏î)
TYPHOON_BASE_URL = "https://api.opentyphoon.ai/v1"
TYPHOON_API_KEY = "sk-vCE2QnUydpGnzic35kI3IcoTsAeWzb2X3jYCCAXDPmfT2JnN"

# 2. Google Gemini (‡πÅ‡∏Å‡πâ‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î - ‡∏â‡∏•‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏ü‡∏£‡∏µ)
GOOGLE_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/openai/"
GOOGLE_API_KEY = "AIzaSyCkjWUucxzLaRPnuklKxKgYP0fUyQhTwHA"
LLM_MODEL_NAME = "gemini-2.0-flash" 

LOCAL_AUDIO_FILE = "soundtest2/‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏∏‡πâ‡∏ô‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô_06_10_2568.mp3"

# 3. Context Biasing (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ASR)
INVESTMENT_PROMPT = (
    "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏∏‡πâ‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô GUNKUL, THAICOM, Nvidia ‡πÅ‡∏•‡∏∞ Tesla "
    "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏î‡∏±‡∏ä‡∏ô‡∏µ SET Index, Fed rate, ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à QoQ, YoY "
    "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ USO Phase, ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏π‡∏• TOR, Budget ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£ Ramp up ‡∏Ç‡∏≠‡∏á Yuanta"
)

# 4. Vocab List (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Reference)
CORRECTION_VOCAB = """
- THAICOM (‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡πÑ‡∏ó‡∏¢‡∏Ñ‡∏° - Ticker: THAICOM)
- GUNKUL (‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏Å‡∏±‡∏ô‡∏Å‡∏∏‡∏• - Ticker: GUNKUL)
- Assumption (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô)
- Quarter (‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™)
- Valuation (‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤)
- SET Index
- Fed (‡πÄ‡∏ü‡∏î)
- Yield (‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô)
- QoQ (Quarter on Quarter - ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏î‡∏ó‡∏¥‡πâ‡∏á)
- YoY (Year on Year - ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏î‡∏ó‡∏¥‡πâ‡∏á)
- USO Phase (‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡∏π‡πÇ‡∏ã ‡πÄ‡∏ü‡∏™ - ‡πÄ‡∏ô‡πá‡∏ï‡∏ä‡∏≤‡∏¢‡∏Ç‡∏≠‡∏ö)
- USO Phase 2 (‡πÄ‡∏ü‡∏™ 2 - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ñ‡∏∑‡∏≠: ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß/‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ/Budget/Ramp up)
- USO Phase 3 (‡πÄ‡∏ü‡∏™ 3 - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ñ‡∏∑‡∏≠: ‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï/‡∏£‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏π‡∏•/TOR/Reaction/‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á)
- TOR (‡∏ó‡∏µ-‡πÇ‡∏≠-‡∏≠‡∏≤‡∏£‡πå / ‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏á‡∏≤‡∏ô)
- Budget (‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì)
- Ramp up (‡πÅ‡∏£‡∏°‡∏õ‡πå‡∏≠‡∏±‡∏û / ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï)
- Yuanta (‡∏ö‡∏•.‡∏´‡∏¢‡∏ß‡∏ô‡∏ï‡πâ‡∏≤)
- Preview (‡∏û‡∏£‡∏µ‡∏ß‡∏¥‡∏ß)
"""

# Chunk Settings (45s/15s Optimized)
CHUNK_DURATION_SEC = 45       
OVERLAP_DURATION_SEC = 15     
CHUNK_DURATION_MS = CHUNK_DURATION_SEC * 1000
OVERLAP_DURATION_MS = OVERLAP_DURATION_SEC * 1000

CACHE_DIR = "yt_cache"
TRANSCRIPT_OUTPUT_DIR = "transcripts_output"
TRANSCRIPT_PREFIX = "final_hybrid_transcript" 
MAX_WORKERS = 5

# ---------------- INIT CLIENTS ----------------

try:
    http_client = httpx.Client(timeout=120.0)
    
    # Client 1: Typhoon (ASR Only)
    asr_client = OpenAI(
        base_url=TYPHOON_BASE_URL,
        api_key=TYPHOON_API_KEY,
        http_client=http_client,
    )
    
    # Client 2: Gemini (LLM Only)
    llm_client = OpenAI(
        base_url=GOOGLE_BASE_URL,
        api_key=GOOGLE_API_KEY,
        http_client=http_client,
    )
    
except Exception as e:
    print(f"‚ùå Error initializing Clients: {e}")
    raise SystemExit

# ---------------- CORE FUNCTIONS ----------------

def get_unique_output_path(prefix, directory, extension=".txt"):
    if not os.path.exists(directory): os.makedirs(directory)
    i = 1
    while True:
        filename = f"{prefix}_{i:02d}{extension}"
        full_path = os.path.join(directory, filename)
        if not os.path.exists(full_path): return full_path
        i += 1

def transcribe_chunk_safe(chunk_data, chunk_index, prompt, max_retries=5):
    print(f"   ‚ñ∂Ô∏è  [Chunk {chunk_index:02d}] Transcribing...")
    retries = 0
    while retries < max_retries:
        try:
            file_like = io.BytesIO(chunk_data)
            file_like.name = f"chunk_{chunk_index}.wav"
            response = asr_client.audio.transcriptions.create(
                model="typhoon-asr-realtime",
                file=file_like,
                language="th",
                prompt=prompt,
            )
            print(f"   ‚úÖ [Chunk {chunk_index:02d}] Done.")
            return response.text
        except (RateLimitError, APITimeoutError) as e:
            retries += 1
            wait_time = (2 * (2 ** retries)) + random.random()
            print(f"   ‚ö†Ô∏è [Chunk {chunk_index:02d}] Retry in {wait_time:.2f}s...")
            time.sleep(wait_time)
        except Exception as e:
            print(f"   ‚ùå [Chunk {chunk_index:02d}] Error: {e}")
            return ""
    return ""

def merge_transcriptions_fuzzy_overlap(transcripts):
    if not transcripts: return ""
    final_text = transcripts[0].strip()
    for i in range(1, len(transcripts)):
        prev_chunk = final_text
        curr_chunk = transcripts[i].strip()
        if not curr_chunk: continue
        check_len = 400 
        prev_suffix = prev_chunk[-check_len:] if len(prev_chunk) > check_len else prev_chunk
        search_range = min(len(curr_chunk), check_len)
        matcher = difflib.SequenceMatcher(None, prev_suffix, curr_chunk[:search_range])
        match = matcher.find_longest_match(0, len(prev_suffix), 0, search_range)
        if match.size > 15:
            trim_idx = match.b + match.size
            text_to_append = curr_chunk[trim_idx:]
            final_text += text_to_append
        else:
            final_text += " " + curr_chunk
    return final_text.replace("  ", " ").strip()

def clean_repetitive_text(text):
    """
    Python Cleaner: ‡∏•‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô (Lookback 3 lines)
    """
    if not text: return ""
    phrases = re.split(r'[\n]+', text) 
    cleaned_phrases = []
    for phrase in phrases:
        phrase = phrase.strip()
        if not phrase: continue
        is_duplicate = False
        lookback_count = 3
        start_check = max(0, len(cleaned_phrases) - lookback_count)
        for prev_phrase in cleaned_phrases[start_check:]:
            if difflib.SequenceMatcher(None, prev_phrase, phrase).ratio() > 0.85:
                is_duplicate = True
                break
        if not is_duplicate:
            cleaned_phrases.append(phrase)
    return "\n".join(cleaned_phrases)

def correct_transcript_with_llm(raw_text, vocab_list):
    print(f"\nüß† Sending to Gemini ({LLM_MODEL_NAME}) for Logic-Based Correction...")
    
    # Pre-cleaning
    hallucination_triggers = [
        "Subtitles by", "Amara.org", "Thank you for watching", 
        "Unidentified speaker", "‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡πÇ‡∏î‡∏¢", "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏ä‡∏°", "‡∏ã‡∏±‡∏ö‡πÑ‡∏ï‡πÄ‡∏ï‡∏¥‡πâ‡∏•‡πÇ‡∏î‡∏¢"
    ]
    for trigger in hallucination_triggers:
        raw_text = raw_text.replace(trigger, "")
    
    raw_text = clean_repetitive_text(raw_text)
    
    # üî• SYSTEM PROMPT: ‡πÉ‡∏ä‡πâ Logic ‡πÅ‡∏ó‡∏ô Rules üî•
    system_prompt = (
        "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏•‡∏≤‡∏î‡∏ó‡∏∏‡∏ô' (Capital Market Specialist) "
        "‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏ö‡∏ó‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏∏‡πâ‡∏ô (Transcript Verification) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ '‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏ç‡∏≤‡∏ì' ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç "
        "‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:"
        "1. **Context Awareness:** ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏Å‡πâ‡πÄ‡∏™‡∏°‡∏≠ ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡πÅ‡∏ö‡∏ö‡∏´‡∏∏‡πà‡∏ô‡∏¢‡∏ô‡∏ï‡πå (Blind Replace)"
        "2. **Entity Recognition:** ‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡πÉ‡∏´‡πâ‡∏≠‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∑‡∏≠ '‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó' (Company) ‡∏Ñ‡∏≥‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∑‡∏≠ '‡∏Ñ‡∏≥‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ' (Common Noun) ‡∏´‡∏£‡∏∑‡∏≠ '‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®' (Country)"
        "3. **Verbatim Integrity:** ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç QoQ/YoY"
    )
    
    user_prompt = f"""
    ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏¥‡∏ö (Raw Transcript):
    \"\"\"{raw_text}\"\"\"
    
    ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç (‡πÉ‡∏ä‡πâ Logic ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏Å‡∏é):
    
    1. **‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô (Ticker Standardization):**
       - ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô **Ticker ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà** (‡πÄ‡∏ä‡πà‡∏ô THAICOM, GUNKUL, ADVANC)
       - ‚ö†Ô∏è **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏±‡πâ‡∏ô‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á **"‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó"** ‡∏´‡∏£‡∏∑‡∏≠ **"‡∏´‡∏∏‡πâ‡∏ô"** ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô 
       - *‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:* "‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢" (‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô), "‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢" (‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô), "‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏Ñ‡∏°" -> "‡∏´‡∏∏‡πâ‡∏ô THAICOM" (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏î‡πâ)
    
    2. **‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô:**
       - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ (‡πÄ‡∏ä‡πà‡∏ô Gooncull -> QoQ, ‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏à‡πá‡∏î -> Budget) ‡πÇ‡∏î‡∏¢‡∏î‡∏π‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
       - ‡∏´‡∏≤‡∏Å‡πÄ‡∏à‡∏≠ "User Facebook" ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÜ ‡πÉ‡∏´‡πâ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:
         * ‡∏ñ‡πâ‡∏≤‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ/‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô -> ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô **USO Phase 2**
         * ‡∏ñ‡πâ‡∏≤‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏π‡∏•/TOR/‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï -> ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô **USO Phase 3**
         * ‡∏ñ‡πâ‡∏≤‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á ‡∏´‡∏¢‡∏ß‡∏ô‡∏ï‡πâ‡∏≤/‡∏´‡∏•‡∏≠‡∏î‡πÉ‡∏ï‡πâ -> ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô **‡∏´‡∏¢‡∏ß‡∏ô‡∏ï‡πâ‡∏≤ (Yuanta)**
         
    3. **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô:**
       - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ QoQ ‡πÅ‡∏•‡∏∞ YoY ‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
       
    4. **‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:**
       - ‡∏à‡∏±‡∏î‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ (‡πÄ‡∏ß‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏≠‡∏≠‡∏Å
    
    ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á (Vocabulary List):
    {vocab_list}
    
    Output: ‡∏Ç‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
    """
    
    try:
        response = llm_client.chat.completions.create(
            model=LLM_MODEL_NAME, 
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1, # ‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏ß‡∏¢ Logic ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÑ‡∏°‡πà‡∏°‡∏±‡πà‡∏ß
            max_tokens=4096 
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"‚ùå LLM Error: {e}")
        return raw_text

# ---------------- MAIN EXECUTION ----------------

def main():
    try:
        # 1. Check File
        if not os.path.exists(LOCAL_AUDIO_FILE):
            print(f"‚ùå File not found: {LOCAL_AUDIO_FILE}")
            return

        print(f"\nüéß Processing: {LOCAL_AUDIO_FILE}")
        audio = AudioSegment.from_file(LOCAL_AUDIO_FILE)
        
        duration_sec = len(audio) / 1000
        file_size = os.path.getsize(LOCAL_AUDIO_FILE) / (1024 * 1024)
        print(f"** Size: {file_size:.2f} MB")
        print(f"** Duration: {int(duration_sec//3600):02d}:{int((duration_sec%3600)//60):02d}:{duration_sec%60:05.2f}")

        # 2. Chunking
        print(f"üì¶ Chunking (Chunk={CHUNK_DURATION_SEC}s, Overlap={OVERLAP_DURATION_SEC}s)...")
        chunks = []
        start = 0
        idx = 0
        while start < len(audio):
            end = min(start + CHUNK_DURATION_MS, len(audio))
            chunk = audio[start:end]
            buf = io.BytesIO()
            chunk.export(buf, format="wav")
            chunks.append({'data': buf.getvalue(), 'index': idx})
            if end == len(audio): break
            start += (CHUNK_DURATION_MS - OVERLAP_DURATION_MS) 
            idx += 1
        print(f"‚úÖ Created {len(chunks)} chunks.")

        # 3. Transcription
        print(f"üöÄ Starting Transcription (Typhoon ASR)...")
        results = {}
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_idx = {
                executor.submit(transcribe_chunk_safe, c['data'], c['index'], INVESTMENT_PROMPT): c['index'] 
                for c in chunks
            }
            for future in concurrent.futures.as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    results[idx] = future.result()
                except Exception:
                    results[idx] = ""

        # 4. Merge
        print("üîÑ Merging text...")
        sorted_text = [results[i] for i in sorted(results.keys())]
        raw_transcript = merge_transcriptions_fuzzy_overlap(sorted_text)
        
        # 5. Correction
        final_output = correct_transcript_with_llm(raw_transcript, CORRECTION_VOCAB)
        
        print("\n" + "="*40)
        print("üìÑ --- FINAL TRANSCRIPTION RESULT ---")
        print("="*40)
        print(final_output) 
        print("="*40 + "\n")
        
        out_path = get_unique_output_path(TRANSCRIPT_PREFIX, TRANSCRIPT_OUTPUT_DIR)
        with open(out_path, "w", encoding="utf-8") as f:
            f.write(final_output)
        print(f"‚úÖ Saved result to: {out_path}")

    except Exception as e:
        print(f"‚ùå Main Error: {e}")

if __name__ == "__main__":
    main()